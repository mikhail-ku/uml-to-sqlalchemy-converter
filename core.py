import os
import getpass
import re
from typing import List, Optional
from dotenv import find_dotenv, load_dotenv
from langchain_gigachat.chat_models import GigaChat
from langchain_core.messages import HumanMessage
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.runnables import RunnableLambda, RunnablePassthrough
from langchain.output_parsers import PydanticOutputParser
from pydantic import BaseModel, Field, validator

# –ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
load_dotenv(find_dotenv())

# –ß—Ç–µ–Ω–∏–µ —Å–∏—Å—Ç–µ–º–Ω–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞ –∏–∑ –≤–Ω–µ—à–Ω–µ–≥–æ —Ñ–∞–π–ª–∞
with open("prompts/system_prompt.txt", encoding="utf-8") as f:
    DEFAULT_SYSTEM_PROMPT = f.read()

# --- –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø –ú–û–î–ï–õ–ò ---
class ModelConfig(BaseModel):
    """–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ GigaChat"""
    name: str = Field("GigaChat-2-Pro", description="–ù–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏")
    temperature: float = Field(0.1, description="–¢–≤–æ—Ä—á–µ—Å—Ç–≤–æ –æ—Ç–≤–µ—Ç–æ–≤ (0-1)")
    max_tokens: Optional[int] = Field(None, description="–ú–∞–∫—Å. —Ç–æ–∫–µ–Ω–æ–≤ –≤ –æ—Ç–≤–µ—Ç–µ")
    verify_ssl: bool = Field(False, description="–ü—Ä–æ–≤–µ—Ä—è—Ç—å SSL —Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç—ã")
    timeout: int = Field(600, description="–¢–∞–π–º–∞—É—Ç –∑–∞–ø—Ä–æ—Å–∞ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö")


# --- –°–¢–†–£–ö–¢–£–†–ê –û–¢–í–ï–¢–ê ---
class SQLAlchemyModels(BaseModel):
    """–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ ORM-–º–æ–¥–µ–ª–∏ SQLAlchemy"""
    code: str = Field(..., description="Python –∫–æ–¥ —Å ORM-–º–æ–¥–µ–ª—è–º–∏ SQLAlchemy 2.x")
    summary: str = Field(..., description="–ö—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –∏ –æ—Ç–Ω–æ—à–µ–Ω–∏–π")
    token_usage: int = Field(0, description="–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ —Ç–æ–∫–µ–Ω–æ–≤")

    @validator('code')
    def code_must_contain_models(cls, v):
        if 'declarative_base' not in v:
            raise ValueError('–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–æ–¥ –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –±–∞–∑–æ–≤—ã–π –∫–ª–∞—Å—Å SQLAlchemy')
        return v


# --- –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø –ü–†–ò–õ–û–ñ–ï–ù–ò–Ø ---
def init_application():
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è —Å –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ–º"""
    print("üîÑ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–Ω–≤–µ—Ä—Ç–µ—Ä–∞ UML –≤ SQLAlchemy ORM")
    print("--------------------------------------------------")

    # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –º–æ–¥–µ–ª–∏
    config = ModelConfig()
    system_prompt = DEFAULT_SYSTEM_PROMPT

    if input("–ò–∑–º–µ–Ω–∏—Ç—å –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –º–æ–¥–µ–ª–∏? (y/n): ").lower() == 'y':
        config.name = input(f"–ú–æ–¥–µ–ª—å ({config.name}): ") or config.name
        config.temperature = float(input(f"Temperature ({config.temperature}): ") or config.temperature)
        config.max_tokens = int(input(f"–ú–∞–∫—Å. —Ç–æ–∫–µ–Ω–æ–≤ ({config.max_tokens}): ") or 0) or None
        config.timeout = int(input(f"–¢–∞–π–º–∞—É—Ç ({config.timeout}): ") or config.timeout)

    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø—Ä–æ–º–ø—Ç–∞
    if input("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫–∞—Å—Ç–æ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç? (y/n): ").lower() == 'y':
        prompt_choice = input("1. –í–≤–µ—Å—Ç–∏ –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É\n2. –í–≤–µ—Å—Ç–∏ —Ç–µ–∫—Å—Ç –ø—Ä–æ–º–ø—Ç–∞\n–í—ã–±–æ—Ä (1/2): ")

        if prompt_choice == '1':
            file_path = input("–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É —Å –ø—Ä–æ–º–ø—Ç–æ–º: ")
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    system_prompt = f.read()
                print("‚úÖ –ü—Ä–æ–º–ø—Ç —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω")
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –ø—Ä–æ–º–ø—Ç–∞: {e}. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –ø—Ä–æ–º–ø—Ç")
        elif prompt_choice == '2':
            print("–í–≤–µ–¥–∏—Ç–µ —Ç–µ–∫—Å—Ç –ø—Ä–æ–º–ø—Ç–∞ (Ctrl+D/Ctrl+Z –¥–ª—è –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è):")
            lines = []
            while True:
                try:
                    line = input()
                except EOFError:
                    break
                lines.append(line)
            system_prompt = "\n".join(lines)
            print("‚úÖ –ü—Ä–æ–º–ø—Ç —É—Å–ø–µ—à–Ω–æ –ø—Ä–∏–Ω—è—Ç")
        else:
            print("‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π –≤—ã–±–æ—Ä. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –ø—Ä–æ–º–ø—Ç")

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä–∞ –≤ –ø—Ä–æ–º–ø—Ç–µ
    if "{format_instructions}" not in system_prompt:
        system_prompt += "\n\n{format_instructions}"
        print("‚ö†Ô∏è –í –ø—Ä–æ–º–ø—Ç –¥–æ–±–∞–≤–ª–µ–Ω –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä {format_instructions}")

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è GigaChat
    if "GIGACHAT_CREDENTIALS" not in os.environ:
        os.environ["GIGACHAT_CREDENTIALS"] = getpass.getpass("üîë –í–≤–µ–¥–∏—Ç–µ –∫–ª—é—á –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏ GigaChat API: ")

    llm = GigaChat(
        model=config.name,
        temperature=config.temperature,
        max_tokens=config.max_tokens,
        verify_ssl_certs=config.verify_ssl,
        timeout=config.timeout
    )

    # –ü–∞—Ä—Å–µ—Ä –¥–ª—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –≤—ã–≤–æ–¥–∞
    parser = PydanticOutputParser(pydantic_object=SQLAlchemyModels)

    return llm, parser, config, system_prompt


# --- –û–°–ù–û–í–ù–ê–Ø –õ–û–ì–ò–ö–ê ---
def build_processing_chain(llm, parser, system_prompt):
    """–°—Ç—Ä–æ–∏—Ç —Ü–µ–ø–æ—á–∫—É –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π"""

    # –§—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–æ–≤
    def upload_files(file_paths: List[str]) -> List[str]:
        file_ids = []
        for path in file_paths:
            try:
                with open(path, "rb") as f:
                    uploaded_file = llm.upload_file(f)
                    file_ids.append(uploaded_file.id_)
                    print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ: {os.path.basename(path)}")
            except Exception as e:
                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ {path}: {str(e)}")
        return file_ids

    # –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–µ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –ø–∞—Ä—Å–µ—Ä–∞
    format_instructions = parser.get_format_instructions()

    # –°–±–æ—Ä–∫–∞ —Ü–µ–ø–æ—á–∫–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏
    prompt = ChatPromptTemplate.from_messages([
        ("system", system_prompt),
        MessagesPlaceholder("history"),
    ]).partial(format_instructions=format_instructions)

    return (
            RunnablePassthrough()
            | RunnableLambda(upload_files)
            | RunnableLambda(lambda ids: {
        "history": [HumanMessage(content="", additional_kwargs={"attachments": ids})]
    })
            | prompt
            | llm
            | parser
    )


# --- –û–ë–†–ê–ë–û–¢–ö–ê –ü–ê–ü–ö–ò –° –ò–ó–û–ë–†–ê–ñ–ï–ù–ò–Ø–ú–ò ---
def process_folder(folder_path: str) -> List[str]:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ UML-–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤ –ø–∞–ø–∫–µ"""
    if not os.path.isdir(folder_path):
        raise ValueError(f"‚ùå –ü–∞–ø–∫–∞ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç: {folder_path}")

    supported_ext = ['.jpg', '.jpeg', '.png', '.bmp']
    return [
        os.path.join(folder_path, f)
        for f in os.listdir(folder_path)
        if os.path.splitext(f)[1].lower() in supported_ext
    ]


# --- –°–û–•–†–ê–ù–ï–ù–ò–ï –†–ï–ó–£–õ–¨–¢–ê–¢–û–í ---
def save_results(models: SQLAlchemyModels, config: ModelConfig, output_filename=None):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏ –≤—ã–≤–æ–¥–∏—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É"""
    if not output_filename:
        output_filename = f"models_{config.name.replace('-', '_')}.py"

    with open(output_filename, "w") as f:
        f.write("# " + models.summary.strip().replace('\n', '\n# ') + "\n\n")
        f.write(models.code)

    print("\n" + "=" * 50)
    print(f"üíæ –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {output_filename}")
    print(f"üîç –°–≤–æ–¥–∫–∞: {models.summary}")
    print(f"üßÆ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ —Ç–æ–∫–µ–Ω–æ–≤: {models.token_usage}")
    print("=" * 50)